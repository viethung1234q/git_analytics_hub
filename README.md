```
 $$$$$$\  $$\   $$\            $$$$$$\                      $$\             $$\     $$\                             $$\   $$\           $$\       
$$  __$$\ \__|  $$ |          $$  __$$\                     $$ |            $$ |    \__|                            $$ |  $$ |          $$ |      
$$ /  \__|$$\ $$$$$$\         $$ /  $$ |$$$$$$$\   $$$$$$\  $$ |$$\   $$\ $$$$$$\   $$\  $$$$$$$\  $$$$$$$\         $$ |  $$ |$$\   $$\ $$$$$$$\  
$$ |$$$$\ $$ |\_$$  _|$$$$$$\ $$$$$$$$ |$$  __$$\  \____$$\ $$ |$$ |  $$ |\_$$  _|  $$ |$$  _____|$$  _____|$$$$$$\ $$$$$$$$ |$$ |  $$ |$$  __$$\ 
$$ |\_$$ |$$ |  $$ |  \______|$$  __$$ |$$ |  $$ | $$$$$$$ |$$ |$$ |  $$ |  $$ |    $$ |$$ /      \$$$$$$\  \______|$$  __$$ |$$ |  $$ |$$ |  $$ |
$$ |  $$ |$$ |  $$ |$$\       $$ |  $$ |$$ |  $$ |$$  __$$ |$$ |$$ |  $$ |  $$ |$$\ $$ |$$ |       \____$$\         $$ |  $$ |$$ |  $$ |$$ |  $$ |
\$$$$$$  |$$ |  \$$$$  |      $$ |  $$ |$$ |  $$ |\$$$$$$$ |$$ |\$$$$$$$ |  \$$$$  |$$ |\$$$$$$$\ $$$$$$$  |        $$ |  $$ |\$$$$$$  |$$$$$$$  |
 \______/ \__|   \____/       \__|  \__|\__|  \__| \_______|\__| \____$$ |   \____/ \__| \_______|\_______/         \__|  \__| \______/ \_______/ 
                                                                $$\   $$ |                                                                        
                                                                \$$$$$$  |                                                                        
                                                                 \______/                                                                         
```
## Description
Git-Analytics-Hub is a tool that automates the collection, processing, and storage of GitHub Archive data, which provide a full record of GitHub activities for public repositories. It runs hourly to download raw data from GitHub Archive. Then, it processes the raw data and aggregates the processed data, both using DuckDB. All the data is stored in MinIO for further analytics.

## Architecture
Git-Analytics-Hub uses muti-tier architecture - the **Medallion Architecture** - which is a data lake design pattern that organises data into three zones:
- **Bronze Zone**: Containing raw, unprocessed data ingested from various sources.
- **Silver Zone**: Containing cleaned, conformed and potentially modeled data.
- **Gold Zone**: Containing aggregated and curated data ready for reporting, dashboards, and advanced analytics.

![Architecture](./images/medallion_architecture.png)

Each zone in Git-Analytics-Hub is responsible for the following:
- **Bronze Zone**: Stores raw data from [GitHub Archive](https://www.gharchive.org/) data in Minio.
- **Silver Zone**: Stores processed data as `.parquet` file. Data is processed by selecting only need fields using DuckDB
- **Gold Zone**: Stores aggregated data as `.parquet` files. Data is aggregated for each day using DuckDB, ready for downstream use.

The workflow is managed using Apache Airflow, ensuring automated and scheduled data processing.

![Architecture](./images/git-analytics-hub_architecture.png)

## Installation

### Prerequisites
Ensure you have the following installed:
- **Docker** (tested with version `28.0.1`)
- **Docker Compose** (tested with version `2.33.1`)
- **Python** (tested with version `3.10.15`)

### Setup
Clone the repository and navigate to the project directory:
```sh
git clone https://github.com/viethung1234q/git_analytics_hub.git
cd git_analytics_hub
```

## Usage

### First-time setup:
Initialize Airflow before running the services:
```sh
docker compose up airflow-init
```
Then, start the services:
```sh
docker compose up --build -d
```

### Subsequent runs:
For all future runs, simply use:
```sh
docker compose up -d
```

### Stop:
To stop services:
```sh
docker compose down
```

## Configuration

### Environment Variables
Environment variables are defined in the `.env` file:
```ini
AIRFLOW_UID=1000
AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT=false
...
```

### Project Configuration
Project-specific configurations are stored in `git_analytics_hub/src/config.ini`:
```ini
[minio]
access_key = minioadmin
secret_key = minioadmin
...
```

## Additional Notes
- Airflow DAGs are configured to run hourly, processing GitHub Archive data.
- Minio is used as object storage for raw and processed data.
- DuckDB serves as the query engine for data transformations.

For detailed documentation and contributions, refer to the official repository.


LÃ½ do nÃªn cÃ i Airflow báº±ng Docker + Docker Compose trÃªn WSL 2 thay vÃ¬ cÃ i trá»±c tiáº¿p báº±ng pip lÃ  vÃ¬:

1. Dá»… dÃ ng quáº£n lÃ½ vÃ  triá»ƒn khai
Táº¥t cáº£ thÃ nh pháº§n cá»§a Airflow (Scheduler, Webserver, Database) Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i trong Docker container, khÃ´ng cáº§n cÃ i Ä‘áº·t thá»§ cÃ´ng PostgreSQL/MySQL hay cÃ¡c dependency khÃ¡c.
Khi cáº§n di chuyá»ƒn Airflow sang mÃ´i trÆ°á»ng khÃ¡c (server, cloud), chá»‰ cáº§n pull Docker image vá» vÃ  cháº¡y.
2. TrÃ¡nh xung Ä‘á»™t mÃ´i trÆ°á»ng
Airflow cÃ³ ráº¥t nhiá»u dependency (SQLAlchemy, Flask, Celery...) dá»… gÃ¢y lá»—i náº¿u cÃ i báº±ng pip trÃªn mÃ´i trÆ°á»ng local.
Náº¿u báº¡n cÃ i Airflow trá»±c tiáº¿p trÃªn WSL 2, cÃ³ thá»ƒ xáº£y ra xung Ä‘á»™t giá»¯a Python version hoáº·c package dependency vá»›i cÃ¡c thÆ° viá»‡n khÃ¡c.
3. Dá»… dÃ ng cáº­p nháº­t vÃ  rollback
Vá»›i Docker, náº¿u cÃ³ báº£n cáº­p nháº­t Airflow, chá»‰ cáº§n thay Ä‘á»•i image version vÃ  restart container, khÃ´ng lo vá» lá»—i do cÃ i Ä‘áº·t thá»§ cÃ´ng.
Náº¿u cÃ³ lá»—i, chá»‰ cáº§n pull láº¡i image cÅ© lÃ  xong.
4. TÃ­ch há»£p dá»… dÃ ng vá»›i Minio vÃ  DuckDB
Báº¡n Ä‘ang dÃ¹ng Minio vÃ  DuckDB, cÃ³ thá»ƒ cháº¡y chÃºng trong cÃ¡c container riÃªng vÃ  káº¿t ná»‘i vá»›i Airflow qua Docker Compose mÃ  khÃ´ng cáº§n cÃ i Ä‘áº·t riÃªng láº».

-> Káº¿t luáº­n: CÃ i Ä‘áº·t báº±ng Docker giÃºp báº¡n dá»… quáº£n lÃ½, dá»… má»Ÿ rá»™ng, khÃ´ng lo lá»—i dependency, phÃ¹ há»£p Ä‘á»ƒ triá»ƒn khai trÃªn báº¥t ká»³ há»‡ thá»‘ng nÃ o. ğŸš€
