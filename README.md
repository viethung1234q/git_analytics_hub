# Git Analytics Hub


   _____ _ _                          _       _   _            _    _       _     
  / ____(_) |       /\               | |     | | (_)          | |  | |     | |    
 | |  __ _| |_     /  \   _ __   __ _| |_   _| |_ _  ___ ___  | |__| |_   _| |__  
 | | |_ | | __|   / /\ \ | '_ \ / _` | | | | | __| |/ __/ __| |  __  | | | | '_ \ 
 | |__| | | |_   / ____ \| | | | (_| | | |_| | |_| | (__\__ \ | |  | | |_| | |_) |
  \_____|_|\__| /_/    \_\_| |_|\__,_|_|\__, |\__|_|\___|___/ |_|  |_|\__,_|_.__/ 
                                         __/ |                                    
                                        |___/                                     

Minio
DuckDB
Gharchive
Hourly fetched data

Incrementally collecting the Github Archive datasets, which provide a full record of GitHub activities for public repositories, and enabling analytics on top of that data.

We will use Medallion architecture/multi-tier architecture for this project. 
The Medallion architecture is a data lake design pattern that organises data into three zones:
- Bronze Zone: Containing raw, unprocessed data ingested from various sources.
- Silver Zone: Containing cleaned, conformed and potentially modeled data.
- Gold Zone: Containing aggregated and curated data ready for reporting, dashboards, and advanced analytics.


python3 src/scripts/fetch_raw_data.py
python3 src/scripts/serialise_raw_data.py
python3 src/scripts/aggregate_tf_data.py


LÃ½ do nÃªn cÃ i Airflow báº±ng Docker + Docker Compose trÃªn WSL 2 thay vÃ¬ cÃ i trá»±c tiáº¿p báº±ng pip lÃ  vÃ¬:

1. Dá»… dÃ ng quáº£n lÃ½ vÃ  triá»ƒn khai
Táº¥t cáº£ thÃ nh pháº§n cá»§a Airflow (Scheduler, Webserver, Database) Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i trong Docker container, khÃ´ng cáº§n cÃ i Ä‘áº·t thá»§ cÃ´ng PostgreSQL/MySQL hay cÃ¡c dependency khÃ¡c.
Khi cáº§n di chuyá»ƒn Airflow sang mÃ´i trÆ°á»ng khÃ¡c (server, cloud), chá»‰ cáº§n pull Docker image vá» vÃ  cháº¡y.
2. TrÃ¡nh xung Ä‘á»™t mÃ´i trÆ°á»ng
Airflow cÃ³ ráº¥t nhiá»u dependency (SQLAlchemy, Flask, Celery...) dá»… gÃ¢y lá»—i náº¿u cÃ i báº±ng pip trÃªn mÃ´i trÆ°á»ng local.
Náº¿u báº¡n cÃ i Airflow trá»±c tiáº¿p trÃªn WSL 2, cÃ³ thá»ƒ xáº£y ra xung Ä‘á»™t giá»¯a Python version hoáº·c package dependency vá»›i cÃ¡c thÆ° viá»‡n khÃ¡c.
3. Dá»… dÃ ng cáº­p nháº­t vÃ  rollback
Vá»›i Docker, náº¿u cÃ³ báº£n cáº­p nháº­t Airflow, chá»‰ cáº§n thay Ä‘á»•i image version vÃ  restart container, khÃ´ng lo vá» lá»—i do cÃ i Ä‘áº·t thá»§ cÃ´ng.
Náº¿u cÃ³ lá»—i, chá»‰ cáº§n pull láº¡i image cÅ© lÃ  xong.
4. TÃ­ch há»£p dá»… dÃ ng vá»›i Minio vÃ  DuckDB
Báº¡n Ä‘ang dÃ¹ng Minio vÃ  DuckDB, cÃ³ thá»ƒ cháº¡y chÃºng trong cÃ¡c container riÃªng vÃ  káº¿t ná»‘i vá»›i Airflow qua Docker Compose mÃ  khÃ´ng cáº§n cÃ i Ä‘áº·t riÃªng láº».

-> Káº¿t luáº­n: CÃ i Ä‘áº·t báº±ng Docker giÃºp báº¡n dá»… quáº£n lÃ½, dá»… má»Ÿ rá»™ng, khÃ´ng lo lá»—i dependency, phÃ¹ há»£p Ä‘á»ƒ triá»ƒn khai trÃªn báº¥t ká»³ há»‡ thá»‘ng nÃ o. ðŸš€


curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.10.5/docker-compose.yaml'
mkdir -p ./airflow
mkdir -p ./airflow/dags ./airflow/logs ./airflow/config ./airflow/plugins
echo -e "AIRFLOW_UID=$(id -u)" > .env
docker compose up airflow-init
docker compose up --build -d


run 1 docker compose to start all service (airflow, minio)